{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WBQcosZ4zd3",
        "outputId": "ad5ef01e-5203-49bc-915c-d89967b6b395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from random import Random\n",
        "from numpy import log,dot,e,shape\n",
        "import math\n",
        "from google.colab import drive\n",
        "#importing csv file \n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/assign/Data Set 1.csv\"\n",
        "data = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Random(10).shuffle(data.values)\n",
        "print(data.shape)\n",
        "# data = data.dropna()\n",
        "print(data.shape)\n",
        "y=data.diagnosis\n",
        "x=data.drop('id',axis=1)\n",
        "x=x.drop('diagnosis',axis=1)\n",
        "\n",
        "x_train=x.iloc[0:382].values\n",
        "x_test=x.iloc[382:].values\n",
        "y_train=y.iloc[0:382].values\n",
        "y_test=y.iloc[382:].values\n",
        "y_binaryTrain=np.array([1.0 if i == 'M' else 0.0 for i in y_train])\n",
        "y_binaryTest=np.array([1.0 if i == 'M' else 0.0 for i in y_test])\n",
        "\n",
        "def standardize_data(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    standardized_data = (data - mean) / std\n",
        "    return standardized_data\n",
        "\n",
        "x_test = standardize_data(x_test)\n",
        "x_train = standardize_data(x_train)\n",
        "\n",
        "mean1 = np.nanmean(x_train)\n",
        "mean2 = np.nanmean(x_test)\n",
        "# Replace NaN values with mean\n",
        "x_train[np.isnan(x_train)] = mean1\n",
        "x_test[np.isnan(x_test)] = mean2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXRlyWVd5Eap",
        "outputId": "1a765f18-76f3-4889-be48-c6c953ae78d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 32)\n",
            "(569, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    # Compute the sigmoid function\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def predict(X, theta, B):\n",
        "    # Make predictions using the logistic regression model\n",
        "    return sigmoid(np.dot(X, theta)+B)\n",
        "\n",
        "def compute_loss(X, y, w, b):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_hat = sigmoid(z)\n",
        "    loss = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
        "    return loss\n",
        "\n",
        "def sgd(X, y, alpha, num_epochs):\n",
        "    # Implement stochastic gradient descent for logistic regression\n",
        "\n",
        "    n_sample, n_features = X.shape\n",
        "    w_i = np.zeros(n_features,dtype=np.float32)\n",
        "    w = w_i\n",
        "    B=0.0\n",
        "    b = B\n",
        "    cost_list =[]\n",
        "    for epoch in range(num_epochs):\n",
        "        for i in range(n_sample):\n",
        "            # Select a random training example\n",
        "            random_index = np.random.randint(n_sample)\n",
        "            xi = X[random_index, :].reshape(1, -1)\n",
        "            yi = y[random_index]\n",
        "\n",
        "            # Compute the predicted probability and loss for the current example\n",
        "            hi = predict(xi, w, B)\n",
        "            loss = -(yi * np.log(hi) + (1 - yi) * np.log(1 - hi))\n",
        "\n",
        "            # Compute the gradient of the loss with respect to the weights\n",
        "            dW = xi.T.dot(hi - yi)\n",
        "            dB = hi-yi\n",
        "            # Update the weights\n",
        "            w -= alpha * dW\n",
        "            b -= alpha * dB \n",
        "            loss = compute_loss(X, y, w, b)\n",
        "            cost_list.append(loss)\n",
        "            # if (epoch%(num_epochs/10) == 0):\n",
        "            #   print(\"cost after \", i, \"iteration is : \", loss)\n",
        "\n",
        "    return w, b, cost_list"
      ],
      "metadata": {
        "id": "m7cB9f7W5lKR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "num_epochs = 500\n",
        "W,B, cost_list = sgd(x_train,y_binaryTrain, alpha, num_epochs)\n",
        "\n",
        "def accuracy(X, Y, W, B):\n",
        "    \n",
        "    Z = np.dot(X, W) + B\n",
        "    A = sigmoid(Z)\n",
        "    \n",
        "    A = A > 0.3\n",
        "    \n",
        "    A = np.array(A, dtype = 'int64')\n",
        "    \n",
        "    acc = (1 - np.sum(np.absolute(A - Y))/Y.shape[0])*100\n",
        "    \n",
        "    print(\"Accuracy of the model is : \", round(acc, 2), \"%\")\n",
        "accuracy(x_test,y_binaryTest,W,B)\n",
        "\n",
        "#plt.plot(range(num_epochs), cost_list)\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9Ok2-4255R7",
        "outputId": "0a935bed-b3ac-4444-c45a-10756ff3eb88"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8fa669b76d03>:12: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
            "<ipython-input-30-8fa669b76d03>:12: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
            "<ipython-input-30-8fa669b76d03>:33: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(yi * np.log(hi) + (1 - yi) * np.log(1 - hi))\n",
            "<ipython-input-30-8fa669b76d03>:33: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(yi * np.log(hi) + (1 - yi) * np.log(1 - hi))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is :  22.99 %\n"
          ]
        }
      ]
    }
  ]
}